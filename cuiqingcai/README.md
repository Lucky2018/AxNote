## 崔庆才的网站

https://cuiqingcai.com/



## 爬虫学习笔记

包括他的网站

搬运的他的视频：

https://www.bilibili.com/video/bv14W411H7HF

https://www.bilibili.com/video/BV1a7411f76Z

他的那本书和GitHub

总之笔记写在这里了





## 大概的目录（视频的）

https://cuiqingcai.com/4320.html



### **一、环境篇**

- Python3+Pip 环境配置
- MongoDB 环境配置
- Redis 环境配置
- MySQL 环境配置
- Python 多版本共存配置
- Python 爬虫常用库的安装

### **二、基础篇**

- 爬虫基本原理
- Urllib 库基本使用
- Requests 库基本使用
- 正则表达式基础
- BeautifulSoup 详解
- PyQuery 详解
- Selenium 详解

### **三、实战篇**

- 使用 Requests + 正则表达式爬取猫眼电影
- 分析 Ajax 请求并抓取今日头条街拍美图
- 使用 Selenium 模拟浏览器抓取淘宝商品美食信息
- 使用 Redis+Flask 维护动态代理池
- 使用代理处理反爬抓取微信文章
- 使用 Redis+Flask 维护动态 Cookies 池

### **四、框架篇**

- PySpider 框架基本使用及抓取 TripAdvisor 实战
- PySpider 架构概述及用法详解
- Scrapy 框架的安装
- Scrapy 框架基本使用
- Scrapy 命令行详解
- Scrapy 中选择器的用法
- Scrapy 中 Spiders 的用法
- Scrapy 中 Item Pipeline 的用法
- Scrapy 中 Download Middleware 的用法
- Scrapy 爬取知乎用户信息实战
- Scrapy+Cookies 池抓取新浪微博
- Scrapy+Tushare 爬取微博股票数据

### **五、分布式篇**

- Scrapy 分布式原理及 Scrapy-Redis 源码解析
- Scrapy 分布式架构搭建抓取知乎
- Scrapy 分布式的部署详解



## 文章的目录

https://cuiqingcai.com/5052.html



- [1 - 开发环境配置](https://cuiqingcai.com/5054.html)
- [1.1-Python3 的安装](https://cuiqingcai.com/5059.html)
- [1.2 - 请求库的安装](https://cuiqingcai.com/5081.html)
- [1.2.1-Requests 的安装](https://cuiqingcai.com/5132.html)
- [1.2.2-Selenium 的安装](https://cuiqingcai.com/5141.html)
- [1.2.3-ChromeDriver 的安装](https://cuiqingcai.com/5135.html)
- [1.2.4-GeckoDriver 的安装](https://cuiqingcai.com/5153.html)
- [1.2.5-PhantomJS 的安装](https://cuiqingcai.com/5159.html)
- [1.2.6-aiohttp 的安装](https://cuiqingcai.com/5163.html)
- [1.3 - 解析库的安装](https://cuiqingcai.com/5168.html)
- [1.3.1-lxml 的安装](https://cuiqingcai.com/5180.html)
- [1.3.2-Beautiful Soup 的安装](https://cuiqingcai.com/5183.html)
- [1.3.3-pyquery 的安装](https://cuiqingcai.com/5186.html)
- [1.3.4-tesserocr 的安装](https://cuiqingcai.com/5189.html)
- [1.4 - 数据库的安装](https://cuiqingcai.com/5197.html)
- [1.4.1-MySQL 的安装](https://cuiqingcai.com/5200.html)
- [1.4.2-MongoDB 安装](https://cuiqingcai.com/5205.html)
- [1.4.3-Redis 的安装](https://cuiqingcai.com/5219.html)
- [1.5 - 存储库的安装](https://cuiqingcai.com/5224.html)
- [1.5.1-PyMySQL 的安装](https://cuiqingcai.com/5227.html)
- [1.5.2-PyMongo 的安装](https://cuiqingcai.com/5230.html)
- [1.5.3-redis-py 的安装](https://cuiqingcai.com/5233.html)
- [1.5.4-RedisDump 的安装](https://cuiqingcai.com/5236.html)
- [1.6-Web 库的安装](https://cuiqingcai.com/5239.html)
- [1.6.1-Flask 的安装](https://cuiqingcai.com/5244.html)
- [1.6.2-Tornado 的安装](https://cuiqingcai.com/5248.html)
- [1.7-App 爬取相关库的安装](https://cuiqingcai.com/5252.html)
- [1.7.1-Charles 的安装](https://cuiqingcai.com/5255.html)
- [1.7.2-mitmproxy 的安装](https://cuiqingcai.com/5391.html)
- [1.7.3-Appium 的安装](https://cuiqingcai.com/5407.html)
- [1.8 - 爬虫框架的安装](https://cuiqingcai.com/5413.html)
- [1.8.1-pyspider 的安装](https://cuiqingcai.com/5416.html)
- [1.8.2-Scrapy 的安装](https://cuiqingcai.com/5421.html)
- [1.8.3-Scrapy-Splash 的安装](https://cuiqingcai.com/5428.html)
- [1.8.4-Scrapy-Redis 的安装](https://cuiqingcai.com/5432.html)
- [1.9 - 部署相关库的安装](https://cuiqingcai.com/5435.html)
- [1.9.1-Docker 的安装](https://cuiqingcai.com/5438.html)
- [1.9.2-Scrapyd 的安装](https://cuiqingcai.com/5445.html)
- [1.9.3-Scrapyd-Client 的安装](https://cuiqingcai.com/5449.html)
- [1.9.4-Scrapyd API 的安装](https://cuiqingcai.com/5453.html)
- [1.9.5-Scrapyrt 的安装](https://cuiqingcai.com/5456.html)
- [1.9.6-Gerapy 的安装](https://cuiqingcai.com/5459.html)
- [2 - 爬虫基础](https://cuiqingcai.com/5462.html)
- [2.1-HTTP 基本原理](https://cuiqingcai.com/5465.html)
- [2.2 - 网页基础](https://cuiqingcai.com/5476.html)
- [2.3 - 爬虫的基本原理](https://cuiqingcai.com/5484.html)
- [2.4 - 会话和 Cookies](https://cuiqingcai.com/5487.html)
- [2.5 - 代理的基本原理](https://cuiqingcai.com/5491.html)
- [3 - 基本库的使用](https://cuiqingcai.com/5494.html)
- [3.1 - 使用 urllib](https://cuiqingcai.com/5497.html)
- [3.1.1 - 发送请求](https://cuiqingcai.com/5500.html)
- [3.1.2 - 处理异常](https://cuiqingcai.com/5505.html)
- [3.1.3 - 解析链接](https://cuiqingcai.com/5508.html)
- [3.1.4 - 分析 Robots 协议](https://cuiqingcai.com/5511.html)
- [3.2 - 使用 requests](https://cuiqingcai.com/5514.html)
- [3.2.1 - 基本用法](https://cuiqingcai.com/5517.html)
- [3.2.2 - 高级用法](https://cuiqingcai.com/5523.html)
- [3.3 - 正则表达式](https://cuiqingcai.com/5530.html)
- [3.4 - 抓取猫眼电影排行](https://cuiqingcai.com/5534.html)
- [4 - 解析库的使用](https://cuiqingcai.com/5542.html)
- [4.1 - 使用 XPath](https://cuiqingcai.com/5545.html)
- [4.2 - 使用 Beautiful Soup](https://cuiqingcai.com/5548.html)
- [4.3 - 使用 pyquery](https://cuiqingcai.com/5551.html)
- [5 - 数据存储](https://cuiqingcai.com/5554.html)
- [5.1 - 文件存储](https://cuiqingcai.com/5557.html)
- [5.1.1-TXT 文本存储](https://cuiqingcai.com/5560.html)
- [5.1.2-JSON 文件存储](https://cuiqingcai.com/5564.html)
- [5.1.3-CSV 文件存储](https://cuiqingcai.com/5571.html)
- [5.2 - 关系型数据库存储](https://cuiqingcai.com/5575.html)
- [5.2.1-MySQL 存储](https://cuiqingcai.com/5578.html)
- [5.3 - 非关系型数据库存储](https://cuiqingcai.com/5581.html)
- [5.3.1-MongoDB 存储](https://cuiqingcai.com/5584.html)
- [5.3.2-Redis 存储](https://cuiqingcai.com/5587.html)
- [6-Ajax 数据爬取](https://cuiqingcai.com/5590.html)
- [6.1 - 什么是 Ajax](https://cuiqingcai.com/5593.html)
- [6.2-Ajax 分析方法](https://cuiqingcai.com/5597.html)
- [6.3-Ajax 结果提取](https://cuiqingcai.com/5609.html)
- [6.4 - 分析 Ajax 爬取今日头条街拍美图](https://cuiqingcai.com/5616.html)
- [7 - 动态渲染页面爬取](https://cuiqingcai.com/5627.html)
- [7.1-Selenium 的使用](https://cuiqingcai.com/5630.html)
- [7.2-Splash 的使用](https://cuiqingcai.com/5638.html)
- [7.3-Splash 负载均衡配置](https://cuiqingcai.com/5654.html)
- [7.4 - 使用 Selenium 爬取淘宝商品](https://cuiqingcai.com/5657.html)
- [8 - 验证码的识别](hhttps://cuiqingcai.com/7032.html)
- [8.1 - 图形验证码的识别](https://cuiqingcai.com/7035.html)
- [8.2 - 极验滑动验证码的识别](https://cuiqingcai.com/7037.html)
- [8.3 - 点触验证码的识别](https://cuiqingcai.com/7039.html)
- [8.4 - 微博宫格验证码的识别](https://cuiqingcai.com/7041.html)
- [9 - 代理的使用](https://cuiqingcai.com/7043.html)
- [9.1 - 代理的设置](https://cuiqingcai.com/7045.html)
- [9.2 - 代理池的维护](https://cuiqingcai.com/7048.html)
- [9.3 - 付费代理的使用](https://cuiqingcai.com/7051.html)
- [9.4-ADSL 拨号代理](https://cuiqingcai.com/8361.html)
- [9.5 - 使用代理爬取微信公众号文章](https://cuiqingcai.com/7844.html)
- [10 - 模拟登录](https://cuiqingcai.com/5678.html)
- [10.1 - 模拟登录并爬取 GitHub](https://cuiqingcai.com/8229.html)
- [10.2-Cookies 池的搭建](https://cuiqingcai.com/8243.html)
- [11-App 的爬取](https://cuiqingcai.com/5678.html)
- [11.1-Charles 的使用](https://cuiqingcai.com/8247.html)
- [11.2-mitmproxy 的使用](https://cuiqingcai.com/8260.html)
- [11.3-mitmdump 爬取 “得到” App 电子书信息](https://cuiqingcai.com/8263.html)
- [11.4-Appium 的基本使用](https://cuiqingcai.com/8290.html)
- [11.5-Appium 爬取微信朋友圈](https://cuiqingcai.com/8293.html)
- [11.6-Appium+mitmdump 爬取京东商品](https://cuiqingcai.com/8306.html)
- [12-pyspider 框架的使用](https://cuiqingcai.com/5678.html)
- [12.1-pyspider 框架介绍](https://cuiqingcai.com/8309.html)
- [12.2-pyspider 的基本使用](https://cuiqingcai.com/8317.html)
- [12.3-pyspider 用法详解](https://cuiqingcai.com/8320.html)
- [13-Scrapy 框架的使用](https://cuiqingcai.com/5678.html)
- [13.1-Scrapy 框架介绍](https://cuiqingcai.com/8364.html)
- [13.2-Scrapy 入门](https://cuiqingcai.com/8337.html)
- [13.3-Selector 的用法](https://cuiqingcai.com/8350.html)
- [13.4-Spider 的用法](https://cuiqingcai.com/8353.html)
- [13.5-Downloader Middleware 的用法](https://cuiqingcai.com/5678.html)
- [13.6-Spider Middleware 的用法](https://cuiqingcai.com/5678.html)
- [13.7-Item Pipeline 的用法](https://cuiqingcai.com/5678.html)
- [13.8-Scrapy 对接 Selenium](https://cuiqingcai.com/5678.html)
- [13.9-Scrapy 对接 Splash](https://cuiqingcai.com/5678.html)
- [13.10-Scrapy 通用爬虫](https://cuiqingcai.com/5678.html)
- [13.11-Scrapyrt 的使用](https://cuiqingcai.com/5678.html)
- [13.12-Scrapy 对接 Docker](https://cuiqingcai.com/5678.html)
- [13.13-Scrapy 爬取新浪微博](https://cuiqingcai.com/5678.html)
- [14 - 分布式爬虫](https://cuiqingcai.com/5678.html)
- [14.1 - 分布式爬虫原理](https://cuiqingcai.com/5678.html)
- [14.2-Scrapy-Redis 源码解析](https://cuiqingcai.com/5678.html)
- [14.3-Scrapy 分布式实现](https://cuiqingcai.com/5678.html)
- [14.4-Bloom Filter 的对接](https://cuiqingcai.com/5678.html)
- [15 - 分布式爬虫的部署](https://cuiqingcai.com/5678.html)
- [15.1-Scrapyd 分布式部署](https://cuiqingcai.com/5678.html)
- [15.2-Scrapyd-Client 的使用](https://cuiqingcai.com/5678.html)
- [15.3-Scrapyd 对接 Docker](https://cuiqingcai.com/5678.html)
- [15.4-Scrapyd 批量部署](https://cuiqingcai.com/5678.html)
- [15.5-Gerapy 分布式管理](https://cuiqingcai.com/5678.html)